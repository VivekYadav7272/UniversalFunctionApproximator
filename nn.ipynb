{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNeuralNetwork:\n",
    "    def __init__(self, input_size: int, hidden_layers: int, nodes_in_each_layer: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.nodes_in_hidden_layer = nodes_in_each_layer\n",
    "\n",
    "        self.weights = [np.random.randn(input_size, nodes_in_each_layer) / np.sqrt(input_size)]\n",
    "        self.bias = [np.random.randn(nodes_in_each_layer, 1)]\n",
    "\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            self.weights.append(np.random.randn(nodes_in_each_layer, nodes_in_each_layer) / np.sqrt(input_size))\n",
    "            self.bias.append(np.random.randn(nodes_in_each_layer, 1))\n",
    "        \n",
    "        self.weights.append(np.random.randn(nodes_in_each_layer, 1) / np.sqrt(input_size))\n",
    "        self.bias.append(np.random.randn(1, 1))\n",
    "\n",
    "    \n",
    "    def forward_propagate(self, input_xs: np.ndarray):\n",
    "        self.num_examples = input_xs.shape[1]\n",
    "        self.activations = [input_xs]\n",
    "        self.Z = []\n",
    "        for i in range(0, self.hidden_layers + 1):\n",
    "            Z: np.ndarray = self.weights[i].T.dot(self.activations[i]) + self.bias[i]\n",
    "            if i != self.hidden_layers:\n",
    "                assert Z.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "            else:\n",
    "                assert Z.shape == (1, self.num_examples)\n",
    "\n",
    "            activation = leaky_relu if i != self.hidden_layers else sigmoid\n",
    "            self.activations.append(activation(Z))\n",
    "            self.Z.append(Z)\n",
    "\n",
    "        self.output = self.activations[-1]\n",
    "        assert self.output.shape == (1, self.num_examples)\n",
    "        # print(self.output)\n",
    "\n",
    "    \n",
    "    def backpropagate(self, inp_ys: np.ndarray, learning_rate: float):\n",
    "        (dL_dOutputW, dL_dOutputB, dL_dA_Lminus1) = self.output_loss(inp_ys)\n",
    "        (dWeights, dBiases) = self.hidden_loss(dL_dA_Lminus1)\n",
    "        # print(f\"dWeights = {dWeights}\\n\\ndBiases = {dBiases}\")\n",
    "\n",
    "        self.weights[-1] -= learning_rate * dL_dOutputW\n",
    "        self.bias[-1] -= learning_rate * dL_dOutputB\n",
    "\n",
    "\n",
    "        for i in range(self.hidden_layers):\n",
    "            # print(i)\n",
    "            self.weights[i] -= learning_rate * dWeights[i]\n",
    "            self.bias[i] -= learning_rate * dBiases[i]\n",
    "            \n",
    "    \n",
    "\n",
    "    def output_loss(self, inp_ys: np.ndarray) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "        # ------------------ For Output Layer, ---------------------------------------\n",
    "\n",
    "        # print(f\"inp_ys = {inp_ys.shape} && self.output == {self.output.shape}\")\n",
    "        assert inp_ys.shape == self.output.shape\n",
    "\n",
    "        dL_dOutputA = -(inp_ys - self.output)\n",
    "        assert dL_dOutputA.shape == (1, self.num_examples)\n",
    "        dA_dOutputZ = sigmoid_derivative(self.activations[-1])\n",
    "        assert dA_dOutputZ.shape == (1, self.num_examples)\n",
    "        \n",
    "        dL_dOutputZ = dL_dOutputA * dA_dOutputZ\n",
    "        assert dL_dOutputZ.shape == (1, self.num_examples)\n",
    "\n",
    "        dOutputZ_dW = self.activations[-2]\n",
    "        assert dOutputZ_dW.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "\n",
    "        # dL_dOutputZ should be broadcasted up for each of the weights\n",
    "        dL_dOutputW = dL_dOutputZ * dOutputZ_dW\n",
    "        assert dL_dOutputW.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "        dL_dOutputW = np.sum(dL_dOutputW, axis=1, keepdims=True) / self.num_examples\n",
    "        assert dL_dOutputW.shape == (self.nodes_in_hidden_layer, 1)\n",
    "\n",
    "        # print(f\"dL_dOutputW = {dL_dOutputW}\")\n",
    "\n",
    "        dL_dOutputB = dL_dOutputZ # (dOutuptZ_dB == 1)\n",
    "        dL_dOutputB = np.sum(dL_dOutputB, axis=1, keepdims=True) / self.num_examples\n",
    "        assert dL_dOutputB.shape == (1, 1)\n",
    "        # print(f\"dL_dOutputB = {dL_dOutputB}\")\n",
    "\n",
    "        # -------------------- Done For Output Layer ---------------------------------------\n",
    "        # Now those are corrections made for this layer, but to propagate error backwards,\n",
    "        # we need to calculate error for the previous nodes as well.\n",
    "\n",
    "        dL_dA_l_1 = dL_dOutputZ * self.weights[-1] # dOutputZ_dA_l_1\n",
    "        assert dL_dA_l_1.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "\n",
    "        return (dL_dOutputW, dL_dOutputB, dL_dA_l_1)\n",
    "    \n",
    "\n",
    "    def hidden_loss(self, dLoss_dA_Lminus1: np.ndarray) -> (list[np.ndarray], list[np.ndarray]):\n",
    "        # dLoss_dA_curr_layer is done for all self.num_examples.\n",
    "        dLoss_dA_curr_layer = dLoss_dA_Lminus1\n",
    "        # print(f\"dLoss_dA_Lminus1 = {dLoss_dA_curr_layer}\")\n",
    "        assert dLoss_dA_curr_layer.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "        \n",
    "        dLoss_dWs = []\n",
    "        dLoss_dBs = []\n",
    "\n",
    "        for i in range(self.hidden_layers - 1, -1, -1):\n",
    "            dA_dZ = leaky_relu_derivative(self.Z[i])\n",
    "            assert dA_dZ.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "            \n",
    "            dLoss_dZ = dLoss_dA_curr_layer * dA_dZ\n",
    "            assert dLoss_dZ.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "\n",
    "            dZ_dW = self.activations[i]\n",
    "            # Really, it should be a 3D array, but it would actually just be a broadcast of each column, putting the examples in the 3rd dimension.\n",
    "            if i != 0:\n",
    "                assert dZ_dW.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "            else:\n",
    "                assert dZ_dW.shape == (self.input_size, self.num_examples)\n",
    "\n",
    "            # What's happening: dLoss_dZ's outer product with dZ_dW and then averaged over all training examples.\n",
    "            # dZ_dW is actually supposed to be a 2D matrix for one example.\n",
    "            # dLoss_dZ is supposed to be a 1D vector for one example.\n",
    "            # dLoss_dZ = [dLoss_dZ1, dLoss_dZ2, ....]\n",
    "            # dZ_dW    =[[dZ_dW00,   dZ_dW01,   dZ_dW02, ..]\n",
    "            #            [dZ_dW10,   dZ_dW11,   dZ_dW12, ..]\n",
    "            #               ...\n",
    "            #           ]\n",
    "            # But if you think about it, it's actually just:\n",
    "            # dZ_dW    =[[A(L-2, 0), A(L-2, 0), A(L-2, 0), ..]\n",
    "            #            [A(L-2, 1), A(L-2, 1), A(L-2, 1), ..]\n",
    "            #            ...\n",
    "            #           ]\n",
    "            # So really, for one example, it's just a 1D vector broadcasted into 2D.                    VVVV 1D part             , 1D part for all examples\n",
    "            # Hence our dZ_dW is technically having all information needed since its dimensions are (self.num_nodes_in_each_layer, self.num_examples).\n",
    "            # So, what we really want dLoss_dW to be is outer product of dLoss_dZ (1D form) and dZ_dW (1D form).\n",
    "            # and then since we have training examples, we average it over all training examples.\n",
    "            # Finally, the resulting weight differential should be arranged as (prev_layer X current_layer),\n",
    "            # and the resulting weight differential out of dL/dZ @ dZ/dW is actually (current_layer X prev_layer), \n",
    "            # so instead we do dZ/dW @ dL/dZ.\n",
    "            # This is what the simple dot product expression is doing. Magic to me how it all worked out almost coincidentally so well.\n",
    "            dLoss_dW = (dZ_dW.dot(dLoss_dZ.T)) / self.num_examples\n",
    "            if i != 0:\n",
    "                assert dLoss_dW.shape == (self.nodes_in_hidden_layer, self.nodes_in_hidden_layer)\n",
    "            else:\n",
    "                assert dLoss_dW.shape == (self.input_size, self.nodes_in_hidden_layer)\n",
    "            \n",
    "            dLoss_dWs.append(dLoss_dW)\n",
    "\n",
    "            dLoss_dB = np.sum(dLoss_dZ, axis=1, keepdims=True) / self.num_examples\n",
    "            assert dLoss_dB.shape == (self.nodes_in_hidden_layer, 1)\n",
    "\n",
    "            dLoss_dBs.append(dLoss_dB)\n",
    "\n",
    "            dLoss_dA_curr_layer = self.weights[i].dot(dLoss_dZ)\n",
    "            \n",
    "            # print(f\"dLoss_dA_curr_layer = {dLoss_dA_curr_layer}\")\n",
    "            \n",
    "            if i != 0:\n",
    "                assert dLoss_dA_curr_layer.shape == (self.nodes_in_hidden_layer, self.num_examples)\n",
    "            else:\n",
    "                assert dLoss_dA_curr_layer.shape == (self.input_size, self.num_examples)\n",
    "\n",
    "        return (list(reversed(dLoss_dWs)), list(reversed(dLoss_dBs)))\n",
    "            \n",
    "\n",
    "def sigmoid(x):\n",
    "    # Check if any element in the matrix is > 100_000\n",
    "    if np.any(x > 100_000):\n",
    "        print(x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(g_x):\n",
    "    return g_x * (1 - g_x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x < 0, 0, 1)\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(0.01*x, x)\n",
    "\n",
    "def leaky_relu_derivative(x: np.ndarray):\n",
    "    return np.where(x < 0, 0.01, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 7 ... 6 5 8]\n",
      " [5 1 5 ... 8 2 6]\n",
      " [1 1 7 ... 6 5 7]] [[0. 0. 0. ... 1. 0. 0.]]\n",
      "Output = [[2.07958668e-07 4.06935475e-07 9.80176894e-04 ... 3.24576555e-05\n",
      "  3.53058699e-05 7.45454572e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.19700028e-07 4.30078633e-07 1.00633618e-03 ... 3.36143736e-05\n",
      "  3.67244251e-05 7.57749941e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.32258143e-07 4.54829699e-07 1.03348541e-03 ... 3.48271034e-05\n",
      "  3.82169300e-05 7.70387263e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.45701176e-07 4.81321706e-07 1.06167384e-03 ... 3.60993282e-05\n",
      "  3.97881775e-05 7.83380329e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.60104038e-07 5.09701111e-07 1.09095472e-03 ... 3.74348021e-05\n",
      "  4.14433719e-05 7.96743940e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.75549074e-07 5.40128521e-07 1.12138428e-03 ... 3.88375708e-05\n",
      "  4.31881160e-05 8.10493582e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.92127173e-07 5.72782192e-07 1.15302342e-03 ... 4.03120210e-05\n",
      "  4.50285562e-05 8.24646247e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.09938276e-07 6.07856296e-07 1.18593575e-03 ... 4.18628663e-05\n",
      "  4.69712239e-05 8.39219034e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.29092628e-07 6.45564545e-07 1.22018892e-03 ... 4.34951968e-05\n",
      "  4.90231750e-05 8.54229916e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.49712220e-07 6.86143771e-07 1.25585571e-03 ... 4.52145343e-05\n",
      "  5.11921099e-05 8.69698261e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.71932217e-07 7.29856513e-07 1.29301489e-03 ... 4.70268747e-05\n",
      "  5.34864175e-05 8.85644889e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.95902406e-07 7.76992733e-07 1.33174969e-03 ... 4.89387161e-05\n",
      "  5.59151860e-05 9.02091544e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.21789327e-07 8.27875933e-07 1.37214863e-03 ... 5.09571293e-05\n",
      "  5.84884582e-05 9.19062143e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.49777721e-07 8.82861509e-07 1.41430727e-03 ... 5.30897801e-05\n",
      "  6.12168900e-05 9.36580462e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.80073567e-07 9.42346024e-07 1.45832820e-03 ... 5.53450306e-05\n",
      "  6.41121997e-05 9.54672368e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.12906797e-07 1.00677185e-06 1.50432166e-03 ... 5.77320082e-05\n",
      "  6.71872297e-05 9.73365641e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.48534444e-07 1.07663260e-06 1.55240619e-03 ... 6.02606843e-05\n",
      "  7.04560284e-05 9.92689878e-03]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.87244360e-07 1.15248007e-06 1.60270946e-03 ... 6.29419688e-05\n",
      "  7.39339849e-05 1.01267665e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[6.29359559e-07 1.23493214e-06 1.65536910e-03 ... 6.57878187e-05\n",
      "  7.76379868e-05 1.03335966e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[6.75243098e-07 1.32468198e-06 1.71053364e-03 ... 6.88113535e-05\n",
      "  8.15865803e-05 1.05477495e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[7.25304032e-07 1.42250916e-06 1.76836404e-03 ... 7.20270016e-05\n",
      "  8.58001922e-05 1.07696118e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[7.80004013e-07 1.52929090e-06 1.82903367e-03 ... 7.54506448e-05\n",
      "  9.03013114e-05 1.09995959e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[8.39872710e-07 1.64606521e-06 1.89278920e-03 ... 7.91000525e-05\n",
      "  9.51175513e-05 1.12382538e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[9.05502218e-07 1.77393969e-06 1.95980991e-03 ... 8.29946369e-05\n",
      "  1.00275408e-04 1.14860168e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[9.77564329e-07 1.91417028e-06 2.03029634e-03 ... 8.71558132e-05\n",
      "  1.05804396e-04 1.17433576e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.05682725e-06 2.06820370e-06 2.10409894e-03 ... 9.16074258e-05\n",
      "  1.11738439e-04 1.20108303e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.14416855e-06 2.23768843e-06 2.18133490e-03 ... 9.63759918e-05\n",
      "  1.18115304e-04 1.22890339e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.24059341e-06 2.42450677e-06 2.26276157e-03 ... 1.01491063e-04\n",
      "  1.24977086e-04 1.25786152e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.34725633e-06 2.63081407e-06 2.34869003e-03 ... 1.06985651e-04\n",
      "  1.32370827e-04 1.28802750e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.46548713e-06 2.85908471e-06 2.43946128e-03 ... 1.12896712e-04\n",
      "  1.40349195e-04 1.31947726e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.59681947e-06 3.11215121e-06 2.53543949e-03 ... 1.19265571e-04\n",
      "  1.48970825e-04 1.35219225e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.74302374e-06 3.39324995e-06 2.63700711e-03 ... 1.26138364e-04\n",
      "  1.58300718e-04 1.38605495e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.90617625e-06 3.70623735e-06 2.74465153e-03 ... 1.33568157e-04\n",
      "  1.68415308e-04 1.42143995e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.08869121e-06 4.05553775e-06 2.85887463e-03 ... 1.41614490e-04\n",
      "  1.79399379e-04 1.45845154e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.29339589e-06 4.44631070e-06 2.98023242e-03 ... 1.50344938e-04\n",
      "  1.91349092e-04 1.49720390e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.52361418e-06 4.88459540e-06 3.10934255e-03 ... 1.59836445e-04\n",
      "  2.04373863e-04 1.53782236e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.78328857e-06 5.37765457e-06 3.24698284e-03 ... 1.70177357e-04\n",
      "  2.18604455e-04 1.58045625e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.07708762e-06 5.93393159e-06 3.39394007e-03 ... 1.81469043e-04\n",
      "  2.34185330e-04 1.62525929e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.41054437e-06 6.56322872e-06 3.55099536e-03 ... 1.93827308e-04\n",
      "  2.51276459e-04 1.67239052e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.79029708e-06 7.27738132e-06 3.71911924e-03 ... 2.07386375e-04\n",
      "  2.70068015e-04 1.72203710e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.22433127e-06 8.09054807e-06 3.89940720e-03 ... 2.22302013e-04\n",
      "  2.90780350e-04 1.77440742e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.72232788e-06 9.01987896e-06 4.09314520e-03 ... 2.38756682e-04\n",
      "  3.13672371e-04 1.83019828e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.29604649e-06 1.00859624e-05 4.30173620e-03 ... 2.56963307e-04\n",
      "  3.39043524e-04 1.88954381e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.95986683e-06 1.13137773e-05 4.52676124e-03 ... 2.77172082e-04\n",
      "  3.67244704e-04 1.95246729e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[6.73152208e-06 1.27339740e-05 4.77006521e-03 ... 2.99679763e-04\n",
      "  3.98691799e-04 2.01930738e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[7.63302521e-06 1.43843516e-05 5.03378558e-03 ... 3.24839911e-04\n",
      "  4.33879646e-04 2.09044985e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[8.69189726e-06 1.63117365e-05 5.32037121e-03 ... 3.53076171e-04\n",
      "  4.73397212e-04 2.16633203e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[9.94289139e-06 1.85750421e-05 5.63270252e-03 ... 3.84901106e-04\n",
      "  5.17961423e-04 2.24746558e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.14301750e-05 2.12481509e-05 5.97412489e-03 ... 4.20936694e-04\n",
      "  5.68429371e-04 2.33442707e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.32104786e-05 2.44250040e-05 6.34857570e-03 ... 4.61945208e-04\n",
      "  6.25845058e-04 2.42788379e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.53575064e-05 2.82265981e-05 6.76074496e-03 ... 5.08870503e-04\n",
      "  6.91498462e-04 2.52862146e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[1.79681060e-05 3.28102372e-05 7.21624622e-03 ... 5.62891995e-04\n",
      "  7.66992040e-04 2.63756494e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.11711808e-05 3.83828565e-05 7.72184755e-03 ... 6.25499437e-04\n",
      "  8.54335633e-04 2.75580968e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[2.51409701e-05 4.52216920e-05 8.28602819e-03 ... 6.98600447e-04\n",
      "  9.56099145e-04 2.88470288e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.01163152e-05 5.37002553e-05 8.91883041e-03 ... 7.84663722e-04\n",
      "  1.07555724e-03 3.02581256e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[3.64309818e-05 6.43339578e-05 9.63300034e-03 ... 8.86939433e-04\n",
      "  1.21699600e-03 3.18109285e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[4.45608781e-05 7.78466998e-05 1.04446961e-02 ... 1.00977961e-03\n",
      "  1.38610106e-03 3.35297085e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[5.52005849e-05 9.52778423e-05 1.13747370e-02 ... 1.15912814e-03\n",
      "  1.59055721e-03 3.54450944e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[6.93886424e-05 1.18143384e-04 1.24490698e-02 ... 1.34327247e-03\n",
      "  1.84074669e-03 3.75952093e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[8.87150920e-05 1.48689762e-04 1.36991191e-02 ... 1.57396251e-03\n",
      "  2.15072569e-03 4.00263846e-02]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00011576 0.00019059 0.01518019 ... 0.00186886 0.00254305 0.04281281]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00015486 0.00024977 0.01696368 ... 0.00225499 0.00305067 0.04605018]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00021365 0.00033649 0.01915538 ... 0.00277593 0.00372576 0.04987618]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00030665 0.00046945 0.02191834 ... 0.00350586 0.00465414 0.0544914 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00046396 0.00068621 0.02552293 ... 0.00458132 0.00599091 0.06022146]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00075641 0.00107211 0.03046253 ... 0.00628239 0.00804886 0.06764802]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00138251 0.00185451 0.03774352 ... 0.00927265 0.01154113 0.07788688]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.00308048 0.00382644 0.04985613 ... 0.01553658 0.01850705 0.09352711]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.01051269 0.01153547 0.07538298 ... 0.03409476 0.03761781 0.12269455]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.0900822  0.07925827 0.15150408 ... 0.13167935 0.12559839 0.19392172]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1253363  0.10691971 0.16831803 ... 0.16196608 0.15063135 0.20794314]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12556931 0.10703395 0.16784752 ... 0.16226808 0.15027504 0.2076842 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12576694 0.10711989 0.16737359 ... 0.1625377  0.14990726 0.20742155]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1259582  0.10719839 0.16690247 ... 0.16280026 0.14954115 0.20716058]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12608932 0.10720693 0.16631626 ... 0.1630257  0.14906544 0.20682107]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12632218 0.10729046 0.16577486 ... 0.16333239 0.14865941 0.2065182 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12650345 0.10731683 0.16514532 ... 0.16360652 0.14816759 0.20615516]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12675973 0.1073985  0.1645553  ... 0.16393932 0.14773239 0.20582393]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12700946 0.1074739  0.16397693 ... 0.16426351 0.1473057  0.20550039]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12725265 0.10754332 0.16341024 ... 0.16457928 0.14688762 0.20518406]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12752219 0.10764368 0.16291796 ... 0.16490602 0.14653873 0.20491811]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12772348 0.10769647 0.16243246 ... 0.16517132 0.14617538 0.2046508 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12791725 0.10774311 0.16195661 ... 0.16542781 0.1458185  0.20439032]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12810439 0.10778387 0.16148917 ... 0.16567647 0.14546729 0.20414013]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12828695 0.10782041 0.16103075 ... 0.16591898 0.14512292 0.20389567]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12843064 0.10780266 0.16046725 ... 0.16614304 0.14468266 0.2035926 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12860826 0.10777375 0.15979744 ... 0.16641018 0.14416836 0.20323781]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12888713 0.10781869 0.15917749 ... 0.16675658 0.14372621 0.20292165]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12916175 0.10786477 0.15859147 ... 0.16709309 0.14331109 0.20262769]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12941067 0.10789748 0.15802863 ... 0.16740293 0.14290839 0.20234523]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12966046 0.10793441 0.15749445 ... 0.16770827 0.14253007 0.20207742]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.12988167 0.10795009 0.1569651  ... 0.16798723 0.14214786 0.20181063]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13009848 0.10796212 0.15644565 ... 0.16826016 0.14177309 0.20154887]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1303109  0.10797081 0.15593584 ... 0.16852716 0.14140559 0.20129189]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13051904 0.10797628 0.15543549 ... 0.16878837 0.14104524 0.20103993]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13072296 0.10797865 0.15494426 ... 0.16904394 0.14069172 0.20079192]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13092309 0.10797813 0.15446195 ... 0.16929428 0.140345   0.20054895]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13113613 0.10799317 0.15403101 ... 0.16954707 0.14004359 0.20033764]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13131214 0.10798211 0.15360584 ... 0.1697662  0.13973643 0.20012622]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1314849  0.10796926 0.15318855 ... 0.16998086 0.13943542 0.19991917]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13165166 0.10796004 0.15277698 ... 0.17018861 0.13914037 0.19971812]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13181379 0.1079482  0.15237204 ... 0.17039083 0.13885001 0.1995204 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13197266 0.10793427 0.15197429 ... 0.17058903 0.13856507 0.19932708]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13212889 0.10791956 0.15158416 ... 0.17078368 0.13828614 0.1991348 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1322826  0.10790353 0.15120096 ... 0.17097465 0.13801235 0.1989462 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13243362 0.10788568 0.15082449 ... 0.17116179 0.13774356 0.1987619 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13258182 0.10786599 0.15045447 ... 0.17134507 0.13747946 0.19858183]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13272755 0.10784466 0.150091   ... 0.17152482 0.13722024 0.19840609]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13287077 0.1078217  0.14973399 ... 0.171701   0.13696589 0.19823443]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13301149 0.10779679 0.14938318 ... 0.17187363 0.13671611 0.19806687]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13315036 0.10777189 0.14904458 ... 0.17204222 0.136476   0.1979084 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13328804 0.10774809 0.14871796 ... 0.17220757 0.13624563 0.19775705]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13343117 0.10773565 0.14842871 ... 0.17237102 0.1360477  0.19763121]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13356206 0.10772179 0.14816878 ... 0.17251863 0.13587071 0.19752108]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13367287 0.10769885 0.1479266  ... 0.17264558 0.13570299 0.19742057]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13377456 0.10767386 0.14770123 ... 0.1727617  0.13554672 0.19733002]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13387581 0.10765451 0.14750059 ... 0.17287301 0.13541096 0.19725522]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13395512 0.10762283 0.14730892 ... 0.17296355 0.1352767  0.19718419]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13404416 0.10760161 0.14713467 ... 0.17305945 0.13515967 0.19712486]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13411743 0.10757275 0.14696961 ... 0.17314    0.13504616 0.19706884]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1341891  0.10754406 0.14681184 ... 0.17321772 0.13493831 0.19701724]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13425382 0.10751045 0.14665646 ... 0.17328868 0.13483064 0.19697398]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13431811 0.10747663 0.14650421 ... 0.17335865 0.13472564 0.19693432]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13438163 0.10744254 0.14635444 ... 0.17342745 0.13462261 0.19689619]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13444464 0.10740953 0.14621526 ... 0.17349362 0.13452825 0.19687377]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13450594 0.10737623 0.14608092 ... 0.17355736 0.13443747 0.19685541]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13457479 0.10735084 0.1459588  ... 0.17362548 0.13435898 0.19684539]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13462895 0.10731946 0.1458491  ... 0.17367864 0.13428694 0.19684164]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13467752 0.10728775 0.14575195 ... 0.17372481 0.13422375 0.19684549]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13472819 0.1072599  0.145663   ... 0.17377139 0.13416807 0.19685409]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13477812 0.10723317 0.14558146 ... 0.1738161  0.13411857 0.19686723]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13482655 0.10720638 0.14550385 ... 0.17385877 0.13407203 0.19688297]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13487071 0.10717717 0.14542859 ... 0.17389744 0.13402654 0.19689969]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13491003 0.10714651 0.14535414 ... 0.17393189 0.13398054 0.19691456]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1349444  0.10711946 0.14528088 ... 0.17396224 0.13393416 0.19692398]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13497724 0.10709166 0.14520876 ... 0.17399102 0.13388836 0.19693399]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13501014 0.10706455 0.14513931 ... 0.17401934 0.13384486 0.19694572]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1350446  0.1070394  0.1450735  ... 0.17404833 0.13380483 0.19695983]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13507591 0.10701214 0.14500773 ... 0.17407455 0.13376405 0.19697379]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13510995 0.10698768 0.14494514 ... 0.17410257 0.13372672 0.19698978]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13514097 0.1069616  0.14488275 ... 0.17412793 0.13368884 0.19700544]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13517273 0.10693574 0.14482268 ... 0.17415325 0.1336531  0.19703458]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13520309 0.10690867 0.14476332 ... 0.17417714 0.13361757 0.19706748]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13523514 0.10688169 0.14470497 ... 0.1742019  0.13358328 0.19711213]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1352679  0.10685572 0.1446462  ... 0.17422634 0.13354745 0.19715787]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13530034 0.10682979 0.14458795 ... 0.17425013 0.13351163 0.19720437]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13533224 0.10680387 0.14453077 ... 0.17427317 0.13347654 0.19725161]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13536374 0.10677813 0.14447596 ... 0.17429547 0.13344327 0.19730071]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13539669 0.10675254 0.14442325 ... 0.17431813 0.13341209 0.19736399]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13542979 0.10672714 0.14437127 ... 0.17434076 0.1333816  0.19742801]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13546269 0.10670186 0.14432032 ... 0.174363   0.13335195 0.19749292]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13549558 0.1066769  0.14427112 ... 0.1743847  0.13332392 0.19755883]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13553032 0.10665235 0.14422305 ... 0.17440675 0.1332981  0.1976245 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13556454 0.10662739 0.1441757  ... 0.17442804 0.13327306 0.19769029]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13559922 0.10660231 0.14412901 ... 0.17444955 0.13324875 0.19776361]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13563066 0.10657848 0.14408184 ... 0.17446962 0.13322317 0.19780556]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13565621 0.10655392 0.14403367 ... 0.17448589 0.13319526 0.19781875]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.1356819  0.10652973 0.14398564 ... 0.17450229 0.13316754 0.19783189]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13570553 0.10650437 0.14393768 ... 0.1745169  0.13313932 0.1978448 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13573181 0.1064801  0.14389097 ... 0.17453328 0.13311286 0.19786849]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13575846 0.1064561  0.14384425 ... 0.1745499  0.13308636 0.19789282]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13578381 0.10643141 0.14379704 ... 0.17456537 0.13305893 0.1979168 ]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13580999 0.10640735 0.14375034 ... 0.17458151 0.13303218 0.19794117]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13583296 0.10638087 0.14370201 ... 0.17459515 0.1330032  0.19796438]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n",
      "Output = [[0.13585876 0.10635675 0.14365551 ... 0.17461093 0.13297648 0.19798897]]\n",
      "Expected = [[0. 0. 0. ... 0. 0. 1.]]\n",
      "Accuracy = 0.87305\n",
      "Number of one classes = 2539.0, total examples = 20000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, train_xs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_propagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_xs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         nn\u001b[38;5;241m.\u001b[39mbackpropagate(train_ys[:, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1000\u001b[39m], \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     20\u001b[0m     nn\u001b[38;5;241m.\u001b[39mforward_propagate(test_xs)\n",
      "Cell \u001b[0;32mIn[56], line 23\u001b[0m, in \u001b[0;36mBinaryNeuralNetwork.forward_propagate\u001b[0;34m(self, input_xs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     Z: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m Z\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes_in_hidden_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_examples)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a neural network to determine if first number is a factor of second or not.\n",
    "nn = BinaryNeuralNetwork(2, 5, 10)\n",
    "# Generate training data.\n",
    "examples = 100_000\n",
    "xs = np.random.randint(0., 10., (2, examples))\n",
    "ys = np.array([float(int(x[1] % x[0] == 0)) for x in xs.T]).reshape(1, examples)\n",
    "# Split into training and testing data as a fraction of examples\n",
    "train_xs = xs[:, :int(0.8 * examples)]\n",
    "train_ys = ys[:, :int(0.8 * examples)]\n",
    "print(train_xs, train_ys)\n",
    "test_xs = xs[:, int(0.8 * examples):]\n",
    "test_ys = ys[:, int(0.8 * examples):]\n",
    "# Train the neural network with 500 examples at a time\n",
    "for _ in range(200):\n",
    "    for i in range(0, train_xs.shape[1], 1000):\n",
    "        nn.forward_propagate(train_xs[:, i:i+1000])\n",
    "        nn.backpropagate(train_ys[:, i:i+1000], 0.01)\n",
    "\n",
    "\n",
    "    nn.forward_propagate(test_xs)\n",
    "    print(f\"Output = {nn.output}\")\n",
    "    print(f\"Expected = {test_ys}\")\n",
    "    print(f\"Accuracy = {np.sum(np.round(nn.output) == test_ys) / test_ys.shape[1]}\")\n",
    "    print(f\"Number of one classes = {np.sum(test_ys)}, total examples = {test_ys.shape[1]}\")\n",
    "    # Test the neural network\n",
    "\n",
    "\n",
    "print(nn.weights)\n",
    "print(nn.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
